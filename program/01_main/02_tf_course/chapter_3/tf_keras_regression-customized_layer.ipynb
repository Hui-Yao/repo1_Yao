{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "sys.version_info(major=3, minor=7, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.3\n",
      "numpy 1.18.1\n",
      "pandas 1.0.3\n",
      "sklearn 0.22.1\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 100), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = tf.keras.layers.Dense(100)\n",
    "layer = tf.keras.layers.Dense(100, input_shape=(None, 5))\n",
    "layer(tf.zeros([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_1/kernel:0' shape=(5, 100) dtype=float32, numpy=\n",
       " array([[-0.12513883, -0.09334002, -0.00205317, -0.17716815, -0.17292383,\n",
       "         -0.03607899, -0.08799517,  0.0417691 ,  0.20919938,  0.05175494,\n",
       "         -0.02914722,  0.14719202,  0.18324383, -0.19422345,  0.2296835 ,\n",
       "          0.13983001,  0.13224141, -0.17693317,  0.03008662,  0.05992602,\n",
       "         -0.2217181 , -0.0958456 , -0.22231561, -0.18248604, -0.11301427,\n",
       "         -0.10896276,  0.19327874, -0.07435647,  0.21152861, -0.04697028,\n",
       "         -0.0239889 ,  0.18736224,  0.09725253, -0.14327371,  0.202404  ,\n",
       "         -0.12570575, -0.17741424, -0.12822437,  0.0513197 , -0.17357844,\n",
       "          0.14501445, -0.20652767,  0.19152598, -0.1777281 , -0.23189436,\n",
       "          0.03355356, -0.00956558,  0.03883408,  0.09448875,  0.02726458,\n",
       "         -0.19028364,  0.02543156,  0.03058498,  0.08026932,  0.14821629,\n",
       "         -0.17706841,  0.00400165, -0.17295448, -0.2351925 , -0.1304814 ,\n",
       "          0.02839194,  0.2048666 ,  0.04042248,  0.22020905,  0.08628593,\n",
       "          0.04106148,  0.12256326,  0.07408319, -0.17291978, -0.10107493,\n",
       "          0.11883615,  0.17534359,  0.15868609,  0.16805412, -0.00299492,\n",
       "         -0.10817733,  0.05922712,  0.11933343, -0.10561419, -0.21052542,\n",
       "          0.21701492,  0.20987736, -0.07557145, -0.12843457,  0.06148158,\n",
       "          0.14665605, -0.21294062, -0.13351053,  0.16749184, -0.1964366 ,\n",
       "         -0.15889153,  0.20712687,  0.19663669, -0.2299953 ,  0.03117172,\n",
       "          0.17978214, -0.138726  , -0.09832542,  0.00223891, -0.1569446 ],\n",
       "        [-0.15803157, -0.13576436,  0.04855154,  0.03739341, -0.23122162,\n",
       "          0.05515371,  0.1197245 , -0.12189913,  0.16799404,  0.22953029,\n",
       "         -0.20787434, -0.23619226, -0.04236405,  0.1030768 , -0.2011151 ,\n",
       "         -0.2366576 , -0.22328547,  0.23861219,  0.18600671, -0.18514642,\n",
       "          0.12406228, -0.18202572, -0.01796582, -0.11510009,  0.2218603 ,\n",
       "         -0.10732034, -0.00930296,  0.11183776, -0.2384131 , -0.1397993 ,\n",
       "          0.19712766, -0.08502452,  0.15889935, -0.16646004, -0.13194722,\n",
       "         -0.06027511, -0.17983188,  0.11241306, -0.02543236, -0.12338277,\n",
       "          0.19881685, -0.07866479,  0.22979464, -0.11209668,  0.14031811,\n",
       "          0.23661663, -0.11131765, -0.09959996, -0.14474958,  0.2080328 ,\n",
       "          0.02504744,  0.11973025, -0.18840761,  0.08001064, -0.00221258,\n",
       "         -0.02846552, -0.14567031,  0.18285115,  0.06805567, -0.21106903,\n",
       "          0.11518548, -0.0499375 ,  0.17474474, -0.22968504, -0.15044445,\n",
       "          0.07903604,  0.09204166,  0.12396996,  0.03812937, -0.14020714,\n",
       "          0.06040327,  0.09912269, -0.05849032,  0.01547246, -0.21887916,\n",
       "          0.13064425, -0.19041854,  0.20896603, -0.03157608,  0.13518892,\n",
       "          0.227924  , -0.03425589,  0.20901181,  0.10385151,  0.06484942,\n",
       "         -0.21757278,  0.08898212,  0.223274  , -0.21893543,  0.16558637,\n",
       "          0.09196438,  0.21245681,  0.17133616,  0.22813721,  0.08024977,\n",
       "         -0.23416342, -0.20617242,  0.10338245, -0.23434575,  0.12441598],\n",
       "        [-0.07078791,  0.15401511,  0.18698679,  0.17265938, -0.11387132,\n",
       "          0.15871327, -0.07531196,  0.1722479 , -0.10511704, -0.05111554,\n",
       "          0.03946994,  0.04275627, -0.00290738,  0.04350312, -0.22477897,\n",
       "          0.21681865, -0.12243258,  0.221963  ,  0.08271153, -0.02181011,\n",
       "         -0.23714194,  0.11739428, -0.16609767, -0.06686105,  0.15635471,\n",
       "         -0.06355454, -0.20333287,  0.14658351,  0.0166433 ,  0.03740345,\n",
       "          0.17018156,  0.03973587,  0.20752738,  0.00175533,  0.04663835,\n",
       "          0.16333391,  0.0810513 ,  0.15857215, -0.1420781 , -0.05787052,\n",
       "         -0.06777561, -0.15820727,  0.18401293,  0.14544894, -0.16271901,\n",
       "          0.02067454,  0.1180668 , -0.08326554,  0.08870398,  0.12908821,\n",
       "         -0.02541378,  0.17940648, -0.17968039,  0.09063594, -0.1441881 ,\n",
       "          0.06156309,  0.20051907,  0.16811053,  0.2230079 , -0.11437748,\n",
       "          0.02756281,  0.21454622, -0.22232234, -0.05193083, -0.09800221,\n",
       "         -0.16601172,  0.09900586, -0.21337183,  0.0123608 ,  0.05283193,\n",
       "         -0.19985414, -0.11981552,  0.12950386,  0.03061353, -0.1011439 ,\n",
       "          0.15941565, -0.18500872,  0.00177538,  0.14054357, -0.01247489,\n",
       "         -0.17347318, -0.08825858,  0.14115731, -0.10526842,  0.09064631,\n",
       "          0.07223074, -0.14162633, -0.0645314 , -0.00237472,  0.00288498,\n",
       "          0.10440792, -0.04466361,  0.00297868,  0.14774211,  0.16954185,\n",
       "         -0.07896411,  0.16549565, -0.1190346 ,  0.02474998,  0.19217981],\n",
       "        [ 0.08789544, -0.08438438, -0.03109114,  0.18415348, -0.06043184,\n",
       "         -0.18396518, -0.1254939 , -0.04723313,  0.06233786,  0.10687973,\n",
       "          0.15867667,  0.23003428, -0.03733613, -0.15682006,  0.21817444,\n",
       "          0.03596894, -0.04401742, -0.0564702 , -0.20127097,  0.13400955,\n",
       "          0.07195221,  0.20988478, -0.1056135 , -0.15985397, -0.13013631,\n",
       "         -0.02707541, -0.15433016,  0.06158896,  0.15155397, -0.13727775,\n",
       "          0.00137849, -0.07477462,  0.11879568, -0.2202087 ,  0.16388331,\n",
       "          0.03323902,  0.21591617,  0.17226084, -0.00220722, -0.20166701,\n",
       "          0.18032579,  0.14349072, -0.04207385,  0.04909624,  0.20159213,\n",
       "         -0.1239246 , -0.171422  , -0.0411358 ,  0.13770624,  0.15063877,\n",
       "          0.2238232 , -0.09311661,  0.1666872 , -0.1211556 ,  0.18641184,\n",
       "          0.13536392,  0.04579507,  0.05440859,  0.03064089, -0.11522793,\n",
       "         -0.03859009,  0.12993725, -0.04328552,  0.1419623 , -0.02388933,\n",
       "         -0.10039751, -0.12956172,  0.07500152, -0.19338019,  0.21924324,\n",
       "         -0.17492336, -0.08848815, -0.17606983,  0.05239145, -0.01466776,\n",
       "          0.20504238,  0.23607986,  0.11959712,  0.2383476 ,  0.06100257,\n",
       "         -0.03363729, -0.1452925 ,  0.18820141,  0.1531109 , -0.05686259,\n",
       "         -0.21873976,  0.02713846, -0.07701741, -0.0415943 ,  0.20138125,\n",
       "          0.0231259 ,  0.07681201, -0.04301423, -0.08821675,  0.16126736,\n",
       "         -0.08051746,  0.07438441,  0.044331  ,  0.04952772,  0.11110882],\n",
       "        [-0.00214824, -0.0367837 , -0.13537927,  0.08906351, -0.16878773,\n",
       "          0.19451128, -0.20614234, -0.00992908,  0.07907932,  0.01388685,\n",
       "         -0.12894443, -0.18131375, -0.23512706,  0.0515814 , -0.08981872,\n",
       "          0.09264795, -0.08384693,  0.03579192,  0.03364898,  0.13775091,\n",
       "         -0.20715162, -0.10012999, -0.19765808,  0.04067592, -0.04479121,\n",
       "          0.13793056,  0.23002107, -0.1392361 , -0.04160741,  0.19679542,\n",
       "         -0.0926185 , -0.05162627, -0.04229087, -0.03071544, -0.08249706,\n",
       "         -0.13643603, -0.03661563,  0.09309547, -0.23716621, -0.21135685,\n",
       "          0.14497979,  0.06614675, -0.1793626 , -0.00589535, -0.13996264,\n",
       "         -0.09500313,  0.01781105,  0.10959975,  0.05323003, -0.07879826,\n",
       "         -0.17708841,  0.07107396, -0.17802903,  0.04442321,  0.17927946,\n",
       "          0.12426428,  0.18015365, -0.19596499, -0.20325883,  0.16094829,\n",
       "          0.18952079, -0.07634108,  0.06852256, -0.1366461 ,  0.05508988,\n",
       "         -0.14928988, -0.01068549, -0.04357013,  0.13974474, -0.17623112,\n",
       "          0.14203028, -0.22799543,  0.0985551 , -0.17264342,  0.09707265,\n",
       "         -0.21717189,  0.18352361, -0.08875819,  0.06423961,  0.02640353,\n",
       "         -0.23881724,  0.10901587, -0.12942448, -0.08657177,  0.21461119,\n",
       "         -0.04885447, -0.04584627,  0.11148508, -0.00069173,  0.10453017,\n",
       "         -0.18819417,  0.02533878,  0.19308855,  0.16892846,  0.01945658,\n",
       "         -0.01160616,  0.15866847, -0.07103521,  0.15584151,  0.00998242]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer.variables\n",
    "# x * w + b\n",
    "layer.trainable_variables\n",
    "\n",
    "# layer中的variable输出的是这一层的所有变量，包括可训练和不可训练变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state = 7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_all, y_train_all, random_state = 11)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.nn.softplus : log(1+e^x)\n",
    "customized_softplus = keras.layers.Lambda(lambda x : tf.nn.softplus(x))\n",
    "print(customized_softplus([-10., -5., 0., 5., 10.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized dense layer.\n",
    "\n",
    "class CustomizedDenseLayer(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        self.units = units\n",
    "        self.activation = keras.layers.Activation(activation)\n",
    "        super(CustomizedDenseLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"构建所需要的参数\"\"\"\n",
    "        # x * w + b. input_shape:[None, a] w:[a,b]output_shape: [None, b]\n",
    "        self.kernel = self.add_weight(name = 'kernel',\n",
    "                                      shape = (input_shape[1], self.units),\n",
    "                                      initializer = 'uniform',\n",
    "                                      trainable = True)\n",
    "\n",
    "        self.bias = self.add_weight(name = 'bias',\n",
    "                                    shape = (self.units, ),\n",
    "                                    initializer = 'zeros',\n",
    "                                    trainable = True)\n",
    "        super(CustomizedDenseLayer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \"\"\"完成正向计算\"\"\"\n",
    "        return self.activation(x @ self.kernel + self.bias)\n",
    "\n",
    "\n",
    "    \n",
    "model = keras.models.Sequential([\n",
    "    CustomizedDenseLayer(30, activation='relu',\n",
    "                         input_shape=x_train.shape[1:]),\n",
    "    CustomizedDenseLayer(1),\n",
    "    customized_softplus,\n",
    "    # keras.layers.Dense(1, activation=\"softplus\"),\n",
    "    # keras.layers.Dense(1), keras.layers.Activation('softplus'),\n",
    "])\n",
    "model.summary()\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "callbacks = [keras.callbacks.EarlyStopping(\n",
    "    patience=5, min_delta=1e-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train_scaled, y_train,\n",
    "                    validation_data = (x_valid_scaled, y_valid),\n",
    "                    epochs = 100,\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
