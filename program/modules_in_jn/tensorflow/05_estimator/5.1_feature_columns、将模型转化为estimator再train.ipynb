{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=6, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.3\n",
      "numpy 1.17.4\n",
      "pandas 1.0.3\n",
      "sklearn 0.22.1\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "# https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
    "# https://storage.googleapis.com/tf-datasets/titanic/eval.csv\n",
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)  #通过pandas读取文件\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "print(type(train_df)) \n",
    "print(train_df.head())  #head（）：默认读取前5行\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train = train_df.pop('survived')  #删除survived(),这时标签，不应该在feature中\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4154670650>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.age.hist(bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f417473f790>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.sex.value_counts().plot(kind = 'barh') # 横的柱状图用'barh',竖的用'barv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f417c1375d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['class'].value_counts().plot(kind = 'barh') # 因为class为关键词，所以要通过键的方式取出'class'的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4174634290>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 统计男性和女性中，分别获救的人数\n",
    "# 因为train_df中含有survived数据，所以设置轴为1\n",
    "# groupby(judge):根据judge来分组\n",
    "# 然后取出survived数据，然后求出均值\n",
    "pd.concat([train_df, y_train], axis = 1).groupby('sex').survived.mean().plot(kind='barh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nunique():\\ntf.feature_column.indicator_column()：转换为one_hot编码\\n\\ncategorical_column_with_vocabulary_list（）：\\n\\ntf.feature_column.\\n\\n\\nnumeric_column\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建feature column\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',  #离散特征\n",
    "                       'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']  #连续特征\n",
    "\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "\n",
    "for categorical_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            categorical_column, dtype=tf.float32))\n",
    "    \n",
    "'''\n",
    "unique():\n",
    "tf.feature_column.indicator_column()：转换为one_hot编码\n",
    "\n",
    "categorical_column_with_vocabulary_list（）：\n",
    "\n",
    "tf.feature_column.\n",
    "\n",
    "\n",
    "numeric_column\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建dataset\n",
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True,\n",
    "                 batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_df, y_train, batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: id=218, shape=(5,), dtype=string, numpy=array([b'male', b'male', b'male', b'male', b'male'], dtype=object)>, 'age': <tf.Tensor: id=210, shape=(5,), dtype=float64, numpy=array([36. , 40.5, 19. , 26. , 34.5])>, 'n_siblings_spouses': <tf.Tensor: id=216, shape=(5,), dtype=int32, numpy=array([0, 0, 0, 0, 0], dtype=int32)>, 'parch': <tf.Tensor: id=217, shape=(5,), dtype=int32, numpy=array([0, 2, 0, 0, 0], dtype=int32)>, 'fare': <tf.Tensor: id=215, shape=(5,), dtype=float64, numpy=array([40.125 , 14.5   ,  7.65  , 18.7875,  6.4375])>, 'class': <tf.Tensor: id=212, shape=(5,), dtype=string, numpy=array([b'First', b'Third', b'Third', b'Third', b'Third'], dtype=object)>, 'deck': <tf.Tensor: id=213, shape=(5,), dtype=string, numpy=array([b'A', b'unknown', b'F', b'unknown', b'unknown'], dtype=object)>, 'embark_town': <tf.Tensor: id=214, shape=(5,), dtype=string, numpy=\n",
      "array([b'Cherbourg', b'Southampton', b'Southampton', b'Cherbourg',\n",
      "       b'Cherbourg'], dtype=object)>, 'alone': <tf.Tensor: id=211, shape=(5,), dtype=string, numpy=array([b'y', b'n', b'y', b'y', b'y'], dtype=object)>} tf.Tensor([0 0 0 1 0], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[62.]\n",
      " [42.]\n",
      " [39.]\n",
      " [40.]\n",
      " [30.]]\n",
      "WARNING:tensorflow:Layer dense_features_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From /home/hui/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/hui/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeature\n",
    "# 可以理解feature_column为对数据进行变换的一组规则，DenseFeature可以将这种规则应用到dataset上的每一个元素\n",
    "# keras.layers.DenseFeatures(age_column)(x)：将数据x应用到数据集x上\n",
    "for x, y in train_dataset.take(1):\n",
    "    age_column = feature_columns[7]\n",
    "    gender_column = feature_columns[0]\n",
    "    print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
    "    print(keras.layers.DenseFeatures(gender_column)(x).numpy())  \n",
    "    # 性别数据原本是字符串（'male', 'female'）,经过feature_column转换后变成了one_hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[[51.    0.    1.    1.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.    0.    0.    0.    8.05  0.    1.    0.    0.    0.\n",
      "   0.    0.    1.    0.    0.    0.    0.    0.    1.    0.  ]\n",
      " [ 6.    1.    0.    0.    0.    1.    1.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.    0.    0.    0.   33.    0.    1.    0.    0.    0.\n",
      "   0.    0.    0.    1.    0.    0.    0.    0.    0.    1.  ]\n",
      " [20.    0.    1.    1.    0.    0.    1.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.    0.    0.    0.    7.05  0.    1.    0.    0.    0.\n",
      "   0.    0.    1.    0.    0.    0.    0.    0.    1.    0.  ]\n",
      " [26.    0.    1.    0.    0.    1.    1.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.    0.    0.    0.   10.5   0.    1.    0.    0.    0.\n",
      "   0.    0.    1.    0.    0.    0.    0.    0.    1.    0.  ]\n",
      " [24.    0.    1.    0.    0.    1.    1.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.    0.    0.    0.   13.    0.    1.    0.    0.    0.\n",
      "   0.    0.    1.    0.    0.    0.    0.    0.    1.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# 直接使用feature_column对所有数据进行转换\n",
    "for x, y in train_dataset.take(1):\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型  \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax'),\n",
    "])\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer = keras.optimizers.SGD(lr=0.01),\n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer sequential_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Train for 20 steps, validate for 8 steps\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 111ms/step - loss: 2.4919 - accuracy: 0.5922 - val_loss: 0.6895 - val_accuracy: 0.6914\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.7142 - accuracy: 0.6687 - val_loss: 0.6077 - val_accuracy: 0.6992\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.6818 - accuracy: 0.6609 - val_loss: 0.6329 - val_accuracy: 0.6953\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.6553 - accuracy: 0.6641 - val_loss: 0.6042 - val_accuracy: 0.6992\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.6279 - accuracy: 0.6672 - val_loss: 0.5991 - val_accuracy: 0.6875\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.6067 - accuracy: 0.7078 - val_loss: 0.5904 - val_accuracy: 0.6953\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5956 - accuracy: 0.6938 - val_loss: 0.5908 - val_accuracy: 0.6992\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.6001 - accuracy: 0.6750 - val_loss: 0.5863 - val_accuracy: 0.6914\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.6038 - accuracy: 0.6672 - val_loss: 0.5903 - val_accuracy: 0.6797\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5823 - accuracy: 0.7047 - val_loss: 0.5834 - val_accuracy: 0.7031\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.5773 - accuracy: 0.6812 - val_loss: 0.5845 - val_accuracy: 0.6875\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.5787 - accuracy: 0.7031 - val_loss: 0.5774 - val_accuracy: 0.6953\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5951 - accuracy: 0.6969 - val_loss: 0.5794 - val_accuracy: 0.6680\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5614 - accuracy: 0.7234 - val_loss: 0.5818 - val_accuracy: 0.7031\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.5968 - accuracy: 0.6969 - val_loss: 0.5852 - val_accuracy: 0.6758\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.6013 - accuracy: 0.6844 - val_loss: 0.5756 - val_accuracy: 0.6953\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.5823 - accuracy: 0.7156 - val_loss: 0.5725 - val_accuracy: 0.6836\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.5748 - accuracy: 0.7047 - val_loss: 0.5686 - val_accuracy: 0.6953\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.5632 - accuracy: 0.7250 - val_loss: 0.5932 - val_accuracy: 0.6797\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.5768 - accuracy: 0.7078 - val_loss: 0.5937 - val_accuracy: 0.6914\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.5571 - accuracy: 0.7266 - val_loss: 0.5778 - val_accuracy: 0.7031\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.5582 - accuracy: 0.7219 - val_loss: 0.5615 - val_accuracy: 0.6992\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.5791 - accuracy: 0.7016 - val_loss: 0.5569 - val_accuracy: 0.6953\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.5810 - accuracy: 0.7141 - val_loss: 0.5554 - val_accuracy: 0.6914\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5713 - accuracy: 0.7328 - val_loss: 0.5697 - val_accuracy: 0.6953\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.5556 - accuracy: 0.7469 - val_loss: 0.5597 - val_accuracy: 0.6992\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5861 - accuracy: 0.7016 - val_loss: 0.5465 - val_accuracy: 0.7188\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.5591 - accuracy: 0.7312 - val_loss: 0.5592 - val_accuracy: 0.7266\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5547 - accuracy: 0.7188 - val_loss: 0.5478 - val_accuracy: 0.7031\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.5803 - accuracy: 0.7281 - val_loss: 0.5516 - val_accuracy: 0.7070\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.5524 - accuracy: 0.7250 - val_loss: 0.5508 - val_accuracy: 0.7461\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5280 - accuracy: 0.7469 - val_loss: 0.5580 - val_accuracy: 0.7344\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 0.5973 - accuracy: 0.6938 - val_loss: 0.6185 - val_accuracy: 0.6680\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.5538 - accuracy: 0.7281 - val_loss: 0.5572 - val_accuracy: 0.7266\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5968 - accuracy: 0.7094 - val_loss: 0.5537 - val_accuracy: 0.7266\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.5257 - accuracy: 0.7234 - val_loss: 0.5765 - val_accuracy: 0.7070\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5889 - accuracy: 0.7031 - val_loss: 0.5350 - val_accuracy: 0.7344\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5317 - accuracy: 0.7641 - val_loss: 0.5309 - val_accuracy: 0.7031\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.5482 - accuracy: 0.7281 - val_loss: 0.5359 - val_accuracy: 0.7188\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.5900 - accuracy: 0.7016 - val_loss: 0.5554 - val_accuracy: 0.7305\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.6075 - accuracy: 0.6859 - val_loss: 0.5364 - val_accuracy: 0.7109\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.5596 - accuracy: 0.7109 - val_loss: 0.5764 - val_accuracy: 0.7188\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5350 - accuracy: 0.7484 - val_loss: 0.5461 - val_accuracy: 0.7227\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.5630 - accuracy: 0.7188 - val_loss: 0.5973 - val_accuracy: 0.7031\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.5822 - accuracy: 0.7141 - val_loss: 0.5777 - val_accuracy: 0.7031\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.5336 - accuracy: 0.7547 - val_loss: 0.5453 - val_accuracy: 0.7148\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5390 - accuracy: 0.7344 - val_loss: 0.5322 - val_accuracy: 0.7148\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5396 - accuracy: 0.7500 - val_loss: 0.5506 - val_accuracy: 0.7188\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.5620 - accuracy: 0.7281 - val_loss: 0.6111 - val_accuracy: 0.6953\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.5538 - accuracy: 0.7312 - val_loss: 0.6807 - val_accuracy: 0.6367\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.5485 - accuracy: 0.7297 - val_loss: 0.5304 - val_accuracy: 0.7227\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.5322 - accuracy: 0.7359 - val_loss: 0.5194 - val_accuracy: 0.7227\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 19ms/step - loss: 0.5346 - accuracy: 0.7469 - val_loss: 0.5500 - val_accuracy: 0.7070\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.5348 - accuracy: 0.7172 - val_loss: 0.6273 - val_accuracy: 0.6953\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5437 - accuracy: 0.7391 - val_loss: 0.5195 - val_accuracy: 0.7070\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.5384 - accuracy: 0.7359 - val_loss: 0.5058 - val_accuracy: 0.7812\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.5212 - accuracy: 0.7422 - val_loss: 0.8932 - val_accuracy: 0.4961\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5348 - accuracy: 0.7547 - val_loss: 0.5252 - val_accuracy: 0.7305\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.5243 - accuracy: 0.7625 - val_loss: 0.5262 - val_accuracy: 0.7305\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5325 - accuracy: 0.7516 - val_loss: 0.5344 - val_accuracy: 0.7383\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5606 - accuracy: 0.7469 - val_loss: 0.5355 - val_accuracy: 0.7227\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5496 - accuracy: 0.7359 - val_loss: 0.5636 - val_accuracy: 0.7109\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.5474 - accuracy: 0.7375 - val_loss: 0.5142 - val_accuracy: 0.7383\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5271 - accuracy: 0.7500 - val_loss: 0.5177 - val_accuracy: 0.7266\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.5383 - accuracy: 0.7453 - val_loss: 0.5288 - val_accuracy: 0.7148\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.5284 - accuracy: 0.7688 - val_loss: 0.5752 - val_accuracy: 0.6953\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5234 - accuracy: 0.7625 - val_loss: 0.5210 - val_accuracy: 0.7188\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.5800 - accuracy: 0.7109 - val_loss: 0.5163 - val_accuracy: 0.7695\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.5231 - accuracy: 0.7453 - val_loss: 0.5538 - val_accuracy: 0.6914\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.5451 - accuracy: 0.7422 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.5148 - accuracy: 0.7578 - val_loss: 0.5081 - val_accuracy: 0.7422\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5312 - accuracy: 0.7469 - val_loss: 0.5186 - val_accuracy: 0.6992\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.5032 - accuracy: 0.7625 - val_loss: 0.5073 - val_accuracy: 0.7344\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.5326 - accuracy: 0.7500 - val_loss: 0.5999 - val_accuracy: 0.6445\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.5651 - accuracy: 0.7156 - val_loss: 0.5102 - val_accuracy: 0.7422\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.5030 - accuracy: 0.7656 - val_loss: 0.5420 - val_accuracy: 0.7188\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.5037 - accuracy: 0.7766 - val_loss: 0.5448 - val_accuracy: 0.7148\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5144 - accuracy: 0.7719 - val_loss: 0.5298 - val_accuracy: 0.7422\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5475 - accuracy: 0.7172 - val_loss: 0.5285 - val_accuracy: 0.7422\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.5388 - accuracy: 0.7500 - val_loss: 0.5037 - val_accuracy: 0.7578\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.5480 - accuracy: 0.7469 - val_loss: 0.5057 - val_accuracy: 0.7266\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5057 - accuracy: 0.7469 - val_loss: 0.5794 - val_accuracy: 0.7188\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.5335 - accuracy: 0.7625 - val_loss: 0.4967 - val_accuracy: 0.7344\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5064 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7773\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.5207 - accuracy: 0.7578 - val_loss: 0.5027 - val_accuracy: 0.7422\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.5657 - accuracy: 0.7219 - val_loss: 0.5177 - val_accuracy: 0.7422\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.5190 - accuracy: 0.7391 - val_loss: 0.5243 - val_accuracy: 0.7344\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.5073 - accuracy: 0.7734 - val_loss: 0.5079 - val_accuracy: 0.7617\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5384 - accuracy: 0.7406 - val_loss: 0.5336 - val_accuracy: 0.7109\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.5245 - accuracy: 0.7609 - val_loss: 0.5666 - val_accuracy: 0.6992\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.5462 - accuracy: 0.7406 - val_loss: 0.4955 - val_accuracy: 0.7383\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5369 - accuracy: 0.7469 - val_loss: 0.5918 - val_accuracy: 0.7188\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.4940 - accuracy: 0.7828 - val_loss: 0.4903 - val_accuracy: 0.7461\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.5315 - accuracy: 0.7531 - val_loss: 0.5161 - val_accuracy: 0.7266\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.5060 - accuracy: 0.7531 - val_loss: 0.5585 - val_accuracy: 0.7148\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.5144 - accuracy: 0.7719 - val_loss: 0.5011 - val_accuracy: 0.7539\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5058 - accuracy: 0.7703 - val_loss: 0.6735 - val_accuracy: 0.6758\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.5599 - accuracy: 0.7484 - val_loss: 0.5008 - val_accuracy: 0.7422\n",
      "Epoch 99/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
      " 0/20 [..............................] - ETA: 0s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Empty training data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-451143b2f11a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     epochs = 100)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m   \u001b[0;31m# End of an epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m   \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Empty training data.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Empty training data."
     ]
    }
   ],
   "source": [
    "#常规fit\n",
    "\n",
    "train_dataset = make_dataset(train_df, y_train, epochs = 100)\n",
    "eval_dataset = make_dataset(eval_df, y_eval, epochs = 1, shuffle = False)\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data = eval_dataset,\n",
    "                    steps_per_epoch = 20,\n",
    "                    validation_steps = 8,\n",
    "                    epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp3puct7vv\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp3puct7vv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f40d9e56f10>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/hui/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/hui/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e32123d7d443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 1. function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 2. return a. (features, labels) b. dataset -> (feature, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m estimator.train(input_fn = lambda : make_dataset(  # 通过lambda函数对make_dataset()进行封装，\n\u001b[0m\u001b[1;32m      6\u001b[0m     train_df, y_train, epochs=100))\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1158\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1188\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1190\u001b[0;31m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1191\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[0;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[0;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m       \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     if all([isinstance(clone, Sequential),\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     return _clone_sequential_model(\n\u001b[0;32m--> 419\u001b[0;31m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[1;32m    420\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     return _clone_functional_model(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    985\u001b[0m                         sparse_tensor.SparseTensor)):\n\u001b[1;32m    986\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[0;32m--> 987\u001b[0;31m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[1;32m    988\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "# 将模型转化为estimator后训练\n",
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "# 1. function\n",
    "# 2. return a. (features, labels) b. dataset -> (feature, label)\n",
    "estimator.train(input_fn = lambda : make_dataset(  # 通过lambda函数对make_dataset()进行封装，\n",
    "    train_df, y_train, epochs=100))\n",
    "\n",
    "'''\n",
    "estimator.train(input_fn = func)\n",
    "参数是一个函数，这个函数不能有参数；\n",
    "返回值需要是一个元组（列表也可以？），其格式为（feature,label）或者数据集（数据集内的元素也要是feature,label）格式）\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9867395276961898360\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17014634552032383916\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"99\"\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    print(device_lib.list_local_devices())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
