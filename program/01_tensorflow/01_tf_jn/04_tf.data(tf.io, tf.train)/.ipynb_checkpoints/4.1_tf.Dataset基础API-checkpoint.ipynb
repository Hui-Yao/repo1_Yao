{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#导入包\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t.Dataset.from_tensor_slices()\n",
    "    适用于数据量较小，能整个装入内存的情况。\n",
    "    具体操作是：将数据通过第零维进行合并（要求所有数据的第零维相同），合并后元素的数量即为第0维的大小。以元祖的形式返回合并后的单个元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((), ()), types: (tf.int32, tf.int32)>\n",
      "2013 12000\n",
      "2014 14000\n",
      "2015 15000\n",
      "2016 16500\n",
      "2017 17500\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant([2013, 2014, 2015, 2016, 2017])\n",
    "Y = tf.constant([12000, 14000, 15000, 16500, 17500])\n",
    "\n",
    "# 也可以使用NumPy数组，效果相同\n",
    "# X = np.array([2013, 2014, 2015, 2016, 2017])\n",
    "# Y = np.array([12000, 14000, 15000, 16500, 17500])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "\n",
    "print(dataset) #TensorSliceDataset型数据\n",
    "\n",
    "for x, y in dataset:\n",
    "    print(x.numpy(), y.numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repeat(count=None)\n",
    "    将数据重复count次。\n",
    "    paras：count：重复次数，tf.int64\n",
    "    \n",
    "# batch(batch_size, drop_remainder=False)\n",
    "    将dataset分成许多份batch_size大小的batches。\n",
    "    paras：~\n",
    "           drop_remainder:如果最后一个batch的元素数量小于batch_size,是否丢弃最后这个batch?\n",
    "                          默认False表示不丢弃，设置为True则丢弃。\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n",
      "**************************************************\n",
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "data = tf.data.Dataset.from_tensor_slices(np.arange(10))\n",
    "data2 = data.repeat(3).batch(5)\n",
    "data3 = data.repeat(3).batch(7)\n",
    "for i in data2:\n",
    "    print(i)\n",
    "print('*'.center(50,'*'))\n",
    "for i in data3:\n",
    "    print(i)\n",
    "'''\n",
    "data2中，10个数据重复3个epoch，每个batch为5个元素，那么刚好6次执行完所有元素\n",
    "data3中，10个数据重复3个epoch，每个batch为7个元素，执行完4个batch后还剩2个元素，所以加上最后那个2个元素的batch，一个5个batch。\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1",
   "language": "python",
   "name": "tensorflow1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
