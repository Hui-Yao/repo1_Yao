{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#tf.constant\n",
    "#\n",
    "const = tf.constant([[1., 2., 3., 4., ], [5., 6., 7., 8., ]])\n",
    "\n",
    "#索引方法\n",
    "print(const)  #constant创建的对象是tf.tensor类型的\n",
    "print(const[:,1:3])\n",
    "print(const[...,1:]) #省略号  ‘...’ 代表前面所有的引号\n",
    "\n",
    "\n",
    "#算术操作\n",
    "#加减乘除是对每个元素进行的；平方是每个元素平方；通过tf.tranpose函数求转置。\n",
    "print(const+10)\n",
    "print(const*2)\n",
    "print(const/3)\n",
    "print(tf.square(const))\n",
    "print(const@tf.transpose(const))\n",
    "\n",
    "\n",
    "#将np.ndarray数据转化为constant类型\n",
    "np_ = np.arange(8).reshape(2,4)\n",
    "np_c = tf.constant(np_)\n",
    "print(type(np_))    #<class 'numpy.ndarray'>\n",
    "print(type(np_c))   #<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
    "\n",
    "\n",
    "#0维数据（scalar）\n",
    "scalar_constant = tf.constant(3.14)\n",
    "print(type(scalar_constant))\n",
    "print(scalar_constant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 string\n",
    "    tf.strings.length(input, unit='BYTE')\n",
    "       作用：是统计字符串的长度。\n",
    "       参数：input：可以使一个字符串，也可以是字符串列表\n",
    "            unit：长度的单位。默认是BYTE（for the number of bytes in each string）；\n",
    "          ‘UTF8_CHAR’表示用编码后的utf8码（for the number of UTF-8 encoded Unicode code points in each string）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strings\n",
    "print('字符串'.center(50,'*'))\n",
    "\n",
    "strings_constant = tf.constant(\"cafe\")\n",
    "print(strings_constant)\n",
    "print(tf.strings.length(strings_constant))\n",
    "print(tf.strings.length(strings_constant, unit=\"UTF8_CHAR\"))\n",
    "print(tf.strings.unicode_decode(strings_constant, \"UTF8\"))\n",
    "\n",
    "# string array\n",
    "t = tf.constant([\"cafe\", \"coffee\", \"咖啡\"])\n",
    "print(tf.strings.length(t, unit=\"UTF8_CHAR\"))\n",
    "r = tf.strings.unicode_decode(t, \"UTF8\")\n",
    "print(r)\n",
    "'''\n",
    "上面第二个输出语句输出的结果是一个二维数据，但是每一行的数据的元素个数不相同，那么把这种数据类型就叫做RaggedTensor\n",
    "<tf.RaggedTensor [[99, 97, 102, 101], [99, 111, 102, 102, 101, 101], [21654, 21857]]>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragged Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ragged tensor\n",
    "print('ragged tensor'.center(50,'*'))\n",
    "r = tf.ragged.constant([[11, 12], [21, 22, 23], [], [41]])\n",
    "# index op\n",
    "print(r)\n",
    "print(r[1])\n",
    "print(r[1:2])\n",
    "\n",
    "#concatenate of ragged tensor\n",
    "r1 = tf.ragged.constant([[1, 2], [3, 5, 6], [], [7, 8]])\n",
    "r2 = tf.ragged.constant([[9, 10,], [11, 12 ,13 ,], [], [14, 15, 16]])\n",
    "r3 = tf.concat([r1, r2], axis = 0) #在零轴上进行拼接即为行的累叠\n",
    "r4 = tf.concat([r1, r2], axis = 1) #在1轴上进行拼接即为宽度上的延伸，能进行拼接的前提是两个对象的行数相同\n",
    "print('r3:',r3)\n",
    "print('r4:',r4)\n",
    "\n",
    "#convert ragged tensor to tensor\n",
    "t5 = r1.to_tensor()\n",
    "print('t5:',t5)\n",
    "#ragged.to_tensor（）方法会把宽度小的行自动补零，以达到和最宽的行一样的宽度，但是实数全都在0的前面。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 sparsetensor\n",
    "    tf.sparse.SparseTensor(indices, values, dense_shape)     \n",
    "    \n",
    "        作用：创建稀疏tensor。\n",
    "        参数：indices:以数组的形式表示非零源的位置\n",
    "             values：以数组的形式输入indices中对应位置的值\n",
    "             dense_shape:以数组的形式指定sparsetensor的shape。\n",
    "             \n",
    "    tf.reorder(a_sparse_tensor)\n",
    "        func:将sparseTensor非零源的索引按照行优先的方法重新排列。\n",
    "        para：a_sparse_tensor\n",
    "        \n",
    "    tf.sparse.saprse_dense_matmul(spa_a,b)\n",
    "        func:将一个sparse_tensor（或密集矩阵）矩阵与一个墨迹矩阵作矩阵乘法\n",
    "        para：spa_a——一个sparse tensor（或一个密集矩阵），b——密集矩阵\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse tensor\n",
    "s1 = tf.sparse.SparseTensor(indices=[[2, 3], [0, 1], [2, 2]], values=[1, 3, 4], dense_shape=[4, 4])\n",
    "print(s1)\n",
    "s2 = tf.sparse.reorder(s1)\n",
    "print(s2)\n",
    "\n",
    "# print('origin:',tf.sparse.to_dense(s1))\n",
    "# 如果sparse_tensor中非零元的indices是混乱的，则不能通过to_dense方法使之转变为位置正确的tensor\n",
    "print('reorder::',tf.sparse.to_dense(s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opration on sparse tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 90. 120.]\n",
      " [  0.   0.]\n",
      " [270. 320.]\n",
      " [  0.   0.]], shape=(4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "s2 = tf.sparse.SparseTensor(indices=[[2, 3], [0, 1], [2, 2]], values=[1., 3., 4.], dense_shape=[4, 4])\n",
    "s4 = tf.constant([[10., 20.],\n",
    "                  [30., 40.],\n",
    "                  [50., 60.],\n",
    "                  [70., 80.]])\n",
    "print(tf.sparse.sparse_dense_matmul(s2, s4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.253px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 381.903818,
   "position": {
    "height": "330.412px",
    "left": "1427.44px",
    "right": "20px",
    "top": "112.963px",
    "width": "320.682px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
